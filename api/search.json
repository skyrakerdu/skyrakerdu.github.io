[{"id":"edfb80c4b09d73ff93916de362feb42e","title":"理解Softmax","content":"1.SoftmaxSoftmax从字面上来说，可以分成soft和max两个部分。max故名思议就是最大值的意思。Softmax的核心在于soft，而soft有软的含义，与之相对的是hard硬。很多场景中需要我们找出数组所有元素中值最大的元素，实质上都是求的hardmax。\nhardmax最大的特点就是只选出其中一个最大的值，即非黑即白。往往在实际中这种方式是不合情理的，比如对于文本分类来说，一篇文章或多或少包含着各种主题信息，我们更期望得到文章对于每个可能的文本类别的概率值（置信度），可以简单理解成属于对应类别的可信度。所以此时用到了soft的概念，Softmax的含义就在于不再唯一的确定某一个最大值，而是为每个输出分类的结果都赋予一个概率值，表示属于每个类别的可能性。\n\n其中  为第i个节点的输出值，C为输出节点的个数，即分类的类别个数。通过Softmax函数就可以将多分类的输出值转换为范围在[0, 1]和为1的概率分布。\n\n引入指数形式的优点\n\n指数函数曲线呈现递增趋势，最重要的是斜率逐渐增大，这种函数曲线能够将输出的数值拉开距离。在深度学习中通常使用反向传播求解梯度进而使用梯度下降进行参数更新的过程，而指数函数在求导的时候比较方便。比如  。\n\n引入指数形式的缺点\n\n指数函数的曲线斜率逐渐增大虽然能够将输出值拉开距离，但是也带来了缺点，当  值非常大的话，计算得到的数值也会变的非常大，数值可能会溢出。\n当然针对数值溢出有其对应的优化方法，将每一个输出值减去输出值中最大的值。\n\n\n当使用Softmax函数作为输出节点的激活函数的时候，一般使用交叉熵作为损失函数。由于Softmax函数的数值计算过程中，很容易因为输出节点的输出值比较大而发生数值溢出的现象，在计算交叉熵的时候也可能会出现数值溢出的问题。为了数值计算的稳定性，TensorFlow提供了一个统一的接口，将Softmax与交叉熵损失函数同时实现，同时也处理了数值不稳定的异常，使用TensorFlow深度学习框架的时候，一般推荐使用这个统一的接口，避免分开使用Softmax函数与交叉熵损失函数。\nimport tensorflow as tf\n\nprint(tf.__version__) # 2.0.0\ntf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits &#x3D; False)\n\n其中y_true代表了One-hot编码后的真实标签，y_pred表示网络的实际预测值：\n\n当from_logits设置为True时，y_pred表示未经Softmax函数的输出值；\n当from_logits设置为False时，y_pred表示为经过Softmax函数后的输出值；\n\n为了在计算Softmax函数时候数值的稳定，一般将from_logits设置为True，此时tf.keras.losses.categorical_crossentropy将在内部进行Softmax的计算，所以在不需要在输出节点上添加Softmax激活函数。\nimport tensorflow as tf\n\nprint(tf.__version__)\nz &#x3D; tf.random.normal([2, 10]) # 构造2个样本的10类别输出的输出值\ny &#x3D; tf.constant([1, 3]) # 两个样本的真是样本标签是1和3\ny_true &#x3D; tf.one_hot(y, depth &#x3D; 10) # 构造onehot编码\n\n# 输出层未经过Softmax激活函数,因此讲from_logits设置为True\nloss1 &#x3D; tf.keras.losses.categorical_crossentropy(y_true, z, from_logits &#x3D; True)\nloss1 &#x3D; tf.reduce_mean(loss1)\nprint(loss1) # tf.Tensor(2.6680193, shape&#x3D;(), dtype&#x3D;float32)\n\ny_pred &#x3D; tf.nn.softmax(z)\n# 输出层经过Softmax激活函数,因此讲from_logits设置为True\nloss2 &#x3D; tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits &#x3D; False)\nloss2 &#x3D; tf.reduce_mean(loss2)\nprint(loss2) # tf.Tensor(2.668019, shape&#x3D;(), dtype&#x3D;float32)\n\n深度学习中常用激活函数总结\n2. Softmax函数求导将Softmax函数表达式  表示为 \n对于Softmax函数的梯度推导依然使用的是导数的基本运算，并不复杂。最关键的是要对 以及  两种情况分别讨论。偏导数的最终表达式如下：\n \n3. 交叉熵损失函数假设此时第i个输出节点为正确类别对应的输出节点，则  是正确类别对应输出节点的概率值。添加  运算不影响函数的单调性，首先为  添加  运算：\n \n由于此时的  是正确类别对应的输出节点的概率，当然希望此时的 越大越好（当然最大不能超过1）。通常情况下使用梯度下降法来迭代求解，因此只需要为  加上一个负号变成损失函数，现在变成希望损失函数越小越好：\n \n对上面的式子进一步处理：\n \n这样就将上面的Softmax一步一步转换成了Softmax的损失函数。\n但是通常我们说起交叉熵往往是下面的式子：\n \n为了方便将第一个  命名为式子1，将通常的交叉熵损失函  数命名为式子2。其实式子1和式子2本质上是一样的。对于式子1来说，只针对正确类别的对应的输出节点，将这个位置的Softmax值最大化，而式子2则是直接衡量真实分布和实际输出的分布之间的距离。\n对于分类任务来说，真实的样本标签通常表示为one-hot的形式。比如对于三分类来说，真实类别的索引位置为1，也就是属于第二个类别，那么使用one-hot编码表示为[0, 1, 0]，也就是仅正确类别位置为1，其余位置都为0。而式子2中的  就是真实样本的标签值，将[0, 1, 0]代入式子2中即 ： \n最终的结果为  ，式子1只是对正确类别位置计算损失值  \n","slug":"理解Softmax","date":"2022-03-11T03:21:58.000Z","categories_index":"Code","tags_index":"Machine Learning","author_index":"skyrakerdu"},{"id":"8e6f1129290e74e0854044fb98335f60","title":"hexo部署成功浏览器看不到新文章","content":"生成静态资源文件，本地执行预览命令，进入预览页面发现一切正常，然后执行部署，也没有报错，只是出现一堆警告而已，最后修改是已经提交到 git remote 仓库的。\nINFO Deploy done: git 也说明了部署操作成功了。那么为什么会出现这个问题呢？\n打开控制台一看 NetWork，发现进入网站所请求的资源都是来自浏览器缓存，状态码都为 200，(from disk cache) or (from memory cache)，这说明了，所有东西都是在客户端缓存请求的，实际上并没有发出 http 请求给服务器.（这里是 github page）这就是强缓存\n解决办法Ctrl-F5 强制刷新第一个解决办法就是 Ctrl-F5 强制刷新，这时请求头的 Cache-Control：no-cache如果没有生效，那就把 localStorage 清空再刷新页面.（一般都是有效的，而不用打开控制台去清空当前页面缓存）\nClear StorageChrome 打开控制台Application,点击clear site data清除站点数据，然后刷新，应该就会出现最新页面了，如果没有出现，那可能就不是缓存的问题。自行 google。\nno-cache &amp; no-storeno-cache 并不是表示不缓存,而是表示强制确认缓存，意味着使用缓存前必须检查这个资源在服务端是否有更新.\n","slug":"hexo部署成功浏览器看不到新文章","date":"2022-01-09T04:20:26.000Z","categories_index":"blogissue","tags_index":"hexo","author_index":"skyrakerdu"},{"id":"d91c256ed1add0da29a666d7c87bdd19","title":"geoserver部分跨域","content":"GEOSERVER : v2.18.0 \nimage：karza\n取消geoserver的跨域注释\n注释tomcat的跨域设置\n","slug":"geoserver部分跨域","date":"2022-01-09T04:04:29.000Z","categories_index":"Code","tags_index":"webgis","author_index":"skyrakerdu"},{"id":"d657fcc76b89f267cff4ec97d3bf7f40","title":"python脚本运行错误","content":"问题：\n最近写水力建模的脚本发现了这样的一个错误，脚本、环境什么的完全正确，但执行的时候却报错：AttributeError: module ‘xxxx’ has no attribute ‘xxxxx’\n问题原因：\n原来是python代码在编译后会生成以pyc为文件名后綴的字节码文件，该字节码文件会经过python解释器来生成机器码文件来运行。当再次运行python文件时，解释器会直接调用该pyc的字节码文件运行直到py文件发生改变（解释器运行时会对比pyc的生成时间和py的修改时间）\n解决方法：\n命名py脚本时，不要与python预留字，模块名等相同\n","slug":"python脚本运行错误","date":"2022-01-09T04:01:59.000Z","categories_index":"Code","tags_index":"python","author_index":"skyrakerdu"},{"id":"fdae0f5223eb5b9ecba9bc2b3b062027","title":"半流食总结","content":"半流质饮食是一种比较稀软烂、易消化、易咀嚼、含粗纤维少、无强烈刺激呈半流质状态的食物。半流食适用于发烧、咀嚼吞咽困难及急性消化道炎症，手术前后以及病情危重的病人。半流质饮食是介于软食与流质饮食之间，外观呈半流体状态，是限量、多餐次进食形式；也称为半流或半流质。\n餐次安排少食多餐，每隔2～3小时进一次餐，每天进餐5～6次。全天主食最好不超过300克。\n主食粥、面条、粉、五谷杂粮糊、馒头（加牛奶泡软）、小馄饨（饺子、大馄饨、烧饼不行）、烂饭、土豆泥（小口）、\n肉类肉末肉泥（猪、牛、鸡）、肝泥（每周吃几次）、龙利鱼、虾仁，采用蒸、煮、炖等烹调方法，要尽可能做得软烂。\n蔬菜白菜、芥菜、胡萝卜、山药、玉米、菠菜、番茄、洋葱、紫薯、南瓜、冬瓜、银耳、莲藕\n水果苹果、橙、猕猴桃、香蕉、百香果、梨、草莓\n高蛋白质类鸡蛋、乳制品、豆腐\n直接购买：五谷杂粮粉、儿童营养米粉、藕粉\n自制食谱：\n粥（糊）：白粥、小米燕麦粥、紫薯粥、地瓜粥、南瓜粥、青菜肉末粥、蔬菜猪肝粥、鸡蛋粥、海鲜粥\n汤：冬瓜肉末汤、西红柿豆腐汤、蛋花汤、香菇肉末汤、鸡肉汤\n菜：鸡蛋羹、小葱拌豆腐、花菜炖豆腐、龙利鱼、茄子\n奶昔：香蕉（红豆）奶昔、黄瓜奶昔、木瓜奶昔、芒果奶昔、黄瓜梨汁、紫薯燕麦奶昔、火龙果奶昔、山药香蕉奶昔\n果汁：当季水果、玉米汁\n米浆：黄豆米浆、黑芝麻豆浆、紫薯燕麦豆浆、\n","slug":"半流食总结","date":"2021-12-08T12:35:08.000Z","categories_index":"日常","tags_index":"饮食","author_index":"skyrakerdu"}]